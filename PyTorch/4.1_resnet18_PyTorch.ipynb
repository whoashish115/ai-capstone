{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8abd2f3a-7930-44bc-9a5f-3646677309bd"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_top\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0b80864-134b-4e19-b978-042c3752181d"
      },
      "source": [
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e5bdfa8-6014-495e-af4c-1905a13cf122"
      },
      "source": [
        "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53741054-55b8-4d99-9976-6032dbb90087"
      },
      "source": [
        "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions:\n",
        "<ul>\n",
        "<li>change the output layer</li>\n",
        "<li> train the model</li>\n",
        "<li>  identify  several  misclassified samples</li>\n",
        " </ul>\n",
        "You will take several screenshots of your work and share your notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba3c08cf-34b0-406d-8125-0593277f34bc"
      },
      "source": [
        "<h2>Table of Contents</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "921f07a2-6a2d-4608-84f2-0cc62bf2501b"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
        "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
        "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
        "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
        "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
        "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
        " </div>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ceb7083-02ed-4c9c-b5b4-7b0418388a2a"
      },
      "source": [
        "<h2 id=\"download_data\">Download Data</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efedf9be-c643-4d62-8158-0918061c6b8b"
      },
      "source": [
        "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3f2804b-7bc0-4a34-a8bd-0756372003da",
        "outputId": "6405c9c7-8d3a-48e3-f3bc-ccae0e3dddf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-24 19:21:29--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2598656062 (2.4G) [application/zip]\n",
            "Saving to: ‘Positive_tensors.zip’\n",
            "\n",
            "Positive_tensors.zi 100%[===================>]   2.42G  37.6MB/s    in 76s     \n",
            "\n",
            "2023-08-24 19:22:45 (32.8 MB/s) - ‘Positive_tensors.zip’ saved [2598656062/2598656062]\n",
            "\n",
            "--2023-08-24 19:25:24--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2111408108 (2.0G) [application/zip]\n",
            "Saving to: ‘Negative_tensors.zip’\n",
            "\n",
            "Negative_tensors.zi 100%[===================>]   1.97G  32.6MB/s    in 64s     \n",
            "\n",
            "2023-08-24 19:26:29 (31.4 MB/s) - ‘Negative_tensors.zip’ saved [2111408108/2111408108]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
        "!unzip -q Positive_tensors.zip\n",
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
        "!unzip -q Negative_tensors.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fad15709-e387-40fd-ab2f-8fde44dea3e1"
      },
      "source": [
        "We will install torchvision:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a4397a6-b3f6-4b0e-b9f9-c0e294eede06",
        "outputId": "15799e9d-3056-49a3-ea3c-2f4548ce177f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "720b2e1a-fa06-4daf-a922-4a70777f6709"
      },
      "source": [
        "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cadbf87-12b4-4cf5-973b-d074375b21f7"
      },
      "source": [
        "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100c4913-0f97-425c-bf42-eba819ed5f7f",
        "outputId": "a75c972d-d258-45e5-c9d1-58ee24a11932"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78aca3326730>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import pandas\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import h5py\n",
        "import os\n",
        "import glob\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "62927ada-7de8-485c-a08e-cb2b038b25d6"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fed9c29-48b2-4bbf-9ba9-7f6fc1c088a2"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7b81ceb-2ff9-4e71-b0ad-bcd507f91029"
      },
      "source": [
        "<h2 id=\"data_class\">Dataset Class</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8630dc80-3ee1-40a4-84d7-0427cd7101c7"
      },
      "source": [
        " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c2612bc-5ed4-4f7d-bc9d-71c6a69ce2b7",
        "outputId": "91785bf2-3977-49a6-f066-6c7237fdf957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# Create your own dataset object\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,transform=None,train=True):\n",
        "        positive_file_path=\"Positive_tensors\"\n",
        "        negative_file_path=\"Negative_tensors\"\n",
        "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
        "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
        "        number_of_samples=len(positive_files)+len(negative_files)\n",
        "        self.all_files=[None]*number_of_samples\n",
        "        self.all_files[::2]=positive_files\n",
        "        self.all_files[1::2]=negative_files\n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        #torch.LongTensor\n",
        "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
        "        self.Y[::2]=1\n",
        "        self.Y[1::2]=0\n",
        "\n",
        "        if train:\n",
        "            self.all_files=self.all_files[0:30000]\n",
        "            self.Y=self.Y[0:30000]\n",
        "            self.len=len(self.all_files)\n",
        "        else:\n",
        "            self.all_files=self.all_files[30000:]\n",
        "            self.Y=self.Y[30000:]\n",
        "            self.len=len(self.all_files)\n",
        "\n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    # Getter\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image=torch.load(self.all_files[idx])\n",
        "        y=self.Y[idx]\n",
        "\n",
        "        # If there is any transform method, apply it onto the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "747173bb-89d3-45e8-b058-ab209f14610c"
      },
      "source": [
        "We create two dataset objects, one for the training data and one for the validation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0618234d-d2a4-459a-aed0-20e3803a4661",
        "outputId": "1edd4a06-1280-42d4-eaa0-d64c9dec3335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(train=True)\n",
        "validation_dataset = Dataset(train=False)\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d03d6186-c5e3-4594-b469-fc776d407fe5"
      },
      "source": [
        "<h2 id=\"Question_1\">Question 1</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67c3bc6f-c9ce-4bc6-98e2-160b4c2c6be3"
      },
      "source": [
        "<b>Prepare a pre-trained resnet18 model :</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cdd3ebc-0de2-4418-9316-a20a12ec7034"
      },
      "source": [
        "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "293cde0f-d36f-4584-a1ff-d4fe736b9fb0",
        "outputId": "59b9e381-a91f-44f7-c687-48a36d7ad74a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 164MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load the pre-trained model resnet18\n",
        "\n",
        "# Type your code here\n",
        "model = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89b310a4-2eb5-4627-ae5e-d0783ba838ad"
      },
      "source": [
        "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22ed14f3-ded5-47a6-b667-34e9d5bc0b95",
        "outputId": "a773d838-8161-4788-e650-10908f70e13f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
        "\n",
        "# Type your code here\n",
        "model.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03f23176-eca4-4e8f-9ec2-a164a5a7ef65"
      },
      "source": [
        "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "410287ff-6594-4af8-8acc-495106d31545"
      },
      "source": [
        "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4f79a8c7-4e3c-48b2-8d5c-75ec66fc7b88"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(512, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "048fe114-92ee-4c41-aede-1e016711ffcd"
      },
      "source": [
        "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1462f12b-da03-4175-ad74-043e46166410",
        "outputId": "1da76839-7509-44ee-ed0d-582be9776379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb183bcf-8cfa-4e48-93e8-af78f42e57b0"
      },
      "source": [
        "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91768582-592a-4360-b47c-1c7db7008ff8"
      },
      "source": [
        "In this question you will train your, model:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8455f1a9-a0af-4502-9179-0a4693cf06d8"
      },
      "source": [
        "<b>Step 1</b>: Create a cross entropy criterion function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5263c76f-483d-42bf-9716-c526278d3fe5"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create the loss function\n",
        "\n",
        "# Type your code here\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a14f9645-a2ff-4900-91e7-4acf3eec2427"
      },
      "source": [
        "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f006c789-b1d6-4eb9-bdc4-613265ac440e"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a965344-294c-4f35-881b-6f3b7e938149"
      },
      "source": [
        "<b>Step 3</b>: Use the following optimizer to minimize the loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4ffbf141-4354-429f-ba64-cf0fecf4d97e"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([parameters for parameters in model.parameters() if parameters.requires_grad], lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "278f8e4c-8cc9-477a-b291-3aedf0d0852e"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a7f9e3b-f4a4-430d-92e4-2b204f4f9162"
      },
      "source": [
        "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e10db4f0-56f4-4c94-940f-133f5764ef04",
        "outputId": "1d7785e0-601d-4db8-bd6a-53f6a069b42e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model... (10 / 300)\n",
            "Training model... (20 / 300)\n",
            "Training model... (30 / 300)\n",
            "Training model... (40 / 300)\n",
            "Training model... (50 / 300)\n",
            "Training model... (60 / 300)\n",
            "Training model... (70 / 300)\n",
            "Training model... (80 / 300)\n",
            "Training model... (90 / 300)\n",
            "Training model... (100 / 300)\n",
            "Training model... (110 / 300)\n",
            "Training model... (120 / 300)\n",
            "Training model... (130 / 300)\n",
            "Training model... (140 / 300)\n",
            "Training model... (150 / 300)\n",
            "Training model... (160 / 300)\n",
            "Training model... (170 / 300)\n",
            "Training model... (180 / 300)\n",
            "Training model... (190 / 300)\n",
            "Training model... (200 / 300)\n",
            "Training model... (210 / 300)\n",
            "Training model... (220 / 300)\n",
            "Training model... (230 / 300)\n",
            "Training model... (240 / 300)\n",
            "Training model... (250 / 300)\n",
            "Training model... (260 / 300)\n",
            "Training model... (270 / 300)\n",
            "Training model... (280 / 300)\n",
            "Training model... (290 / 300)\n",
            "Training model... (300 / 300)\n",
            "Validating model... (10 / 100)\n",
            "Validating model... (20 / 100)\n",
            "Validating model... (30 / 100)\n",
            "Validating model... (40 / 100)\n",
            "Validating model... (50 / 100)\n",
            "Validating model... (60 / 100)\n",
            "Validating model... (70 / 100)\n",
            "Validating model... (80 / 100)\n",
            "Validating model... (90 / 100)\n",
            "Validating model... (100 / 100)\n",
            "Training model... (10 / 300)\n",
            "Training model... (20 / 300)\n",
            "Training model... (30 / 300)\n",
            "Training model... (40 / 300)\n",
            "Training model... (50 / 300)\n",
            "Training model... (60 / 300)\n",
            "Training model... (70 / 300)\n",
            "Training model... (80 / 300)\n",
            "Training model... (90 / 300)\n",
            "Training model... (100 / 300)\n",
            "Training model... (110 / 300)\n",
            "Training model... (120 / 300)\n",
            "Training model... (130 / 300)\n",
            "Training model... (140 / 300)\n",
            "Training model... (150 / 300)\n",
            "Training model... (160 / 300)\n",
            "Training model... (170 / 300)\n",
            "Training model... (180 / 300)\n",
            "Training model... (190 / 300)\n",
            "Training model... (200 / 300)\n",
            "Training model... (210 / 300)\n",
            "Training model... (220 / 300)\n",
            "Training model... (230 / 300)\n",
            "Training model... (240 / 300)\n",
            "Training model... (250 / 300)\n",
            "Training model... (260 / 300)\n",
            "Training model... (270 / 300)\n",
            "Training model... (280 / 300)\n",
            "Training model... (290 / 300)\n",
            "Training model... (300 / 300)\n",
            "Validating model... (10 / 100)\n",
            "Validating model... (20 / 100)\n",
            "Validating model... (30 / 100)\n",
            "Validating model... (40 / 100)\n",
            "Validating model... (50 / 100)\n",
            "Validating model... (60 / 100)\n",
            "Validating model... (70 / 100)\n",
            "Validating model... (80 / 100)\n",
            "Validating model... (90 / 100)\n",
            "Validating model... (100 / 100)\n"
          ]
        }
      ],
      "source": [
        "n_epochs=2\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "correct=0\n",
        "N_test=len(validation_dataset)\n",
        "N_train=len(train_dataset)\n",
        "start_time = time.time()\n",
        "\n",
        "Loss=0\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    count_train = 0\n",
        "    for x, y in train_loader:\n",
        "        count_train += 1\n",
        "        if count_train % 10 == 0:\n",
        "            print(f\"Training model... ({count_train} / {len(train_loader)})\")\n",
        "        # set model to train\n",
        "        model.train()\n",
        "        # clear gradient\n",
        "        optimizer.zero_grad()\n",
        "        # make a prediction\n",
        "        z = model(x)\n",
        "        # calculate loss\n",
        "        loss = criterion(z, y)\n",
        "        # calculate gradients of parameters\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        loss_list.append(loss.data)\n",
        "    correct=0\n",
        "    count_val = 0\n",
        "    for x_test, y_test in validation_loader:\n",
        "        count_val += 1\n",
        "        if count_val % 10 == 0:\n",
        "            print(f\"Validating model... ({count_val} / {len(validation_loader)})\")\n",
        "        # set model to eval\n",
        "        model.eval()\n",
        "        # make a prediction\n",
        "        z = model(x_test)\n",
        "        # find max\n",
        "        _, yhat = torch.max(z.data, 1)\n",
        "        # Calculate misclassified samples in mini-batch\n",
        "        correct += (yhat == y_test).sum().item()\n",
        "    accuracy=correct/N_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "176f3003-c65d-40bc-96ad-5c9c48c99f3b"
      },
      "source": [
        "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "f321eee5-544b-4659-839f-0e6ea591d09d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dca39d5-b83c-473b-f063-4677fc135f13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9962"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3c7ae1d7-abbd-4e21-b0f2-9e45b967a1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "b716357a-e24f-44ee-dee1-9bd380a31499"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7f1f6bc-f2ba-4b06-9109-7778966e1379"
      },
      "source": [
        "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a78f947-6f88-4871-8005-d5732cd8e2d9"
      },
      "source": [
        "<b>Identify the first four misclassified samples using the validation data:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6d0864db-4423-447e-b379-407e707efb43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590c360e-dda2-47cc-9259-cdbdd81e6226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassified sample #327: predicted Positive, actual Negative\n",
            "Misclassified sample #719: predicted Positive, actual Negative\n",
            "Misclassified sample #760: predicted Negative, actual Positive\n",
            "Misclassified sample #821: predicted Positive, actual Negative\n"
          ]
        }
      ],
      "source": [
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n",
        "misclassified = 0\n",
        "count = 0\n",
        "for x, y in validation_loader:\n",
        "    z = model(x)\n",
        "    _, yhat = torch.max(z, 1)\n",
        "    count += 1\n",
        "    if yhat==y: continue\n",
        "    misclassified += 1\n",
        "    prediction = 'Negative' if yhat[0]==0 else 'Positive'\n",
        "    truth = 'Negative' if y[0]==0 else 'Positive'\n",
        "    print(f\"Misclassified sample #{count-1}: predicted {prediction}, actual {truth}\")\n",
        "    if misclassified>=4: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "715b8fe6-26bd-4bb9-b8da-1ca492528ee6"
      },
      "source": [
        "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46f20a3f-7d1b-4aea-9e74-e373ec30e1bb"
      },
      "source": [
        "<h2>About the Authors:</h2>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acb64cce-3fe5-489d-bced-79c3e7a447cf"
      },
      "source": [
        "\n",
        "## Change Log\n",
        "\n",
        "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
        "|---|---|---|---|\n",
        "| 2020-09-21  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a379170-e56f-40f9-9f8f-e3227416419a"
      },
      "source": [
        "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">MIT License</a>.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}