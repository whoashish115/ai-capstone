{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77887c9d-c2ff-4dd4-b2c6-64bfa1984219"
      },
      "source": [
        "<a href=\"https://cognitiveclass.ai/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"400\"> </a>\n",
        "\n",
        "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13b30d7e-8769-497a-8ff3-410157a58567"
      },
      "source": [
        "## Objective\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "373dcde3-aeb9-47f2-95b4-832192acc8de"
      },
      "source": [
        "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc030d9b-7972-4688-86b1-205951d1163b"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "    \n",
        "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
        "2. <a href=\"#item32\">Download Data</a>  \n",
        "3. <a href=\"#item33\">Define Global Constants</a>  \n",
        "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
        "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
        "\n",
        "</font>\n",
        "    \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d762fa9-3236-411c-af87-b8de53f576a8"
      },
      "source": [
        "<a id='item31'></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skillsnetwork"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yIbVuc7cC-6",
        "outputId": "15e32796-687d-4881-aff6-f7a7521364f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skillsnetwork\n",
            "  Downloading skillsnetwork-0.20.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (7.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (2.31.0)\n",
            "Requirement already satisfied: tqdm<5,>=4 in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (4.66.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->skillsnetwork) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->skillsnetwork) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->skillsnetwork) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->skillsnetwork) (3.6.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->skillsnetwork) (3.0.8)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->skillsnetwork)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (2023.7.22)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (6.3.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->skillsnetwork) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->skillsnetwork) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->skillsnetwork) (0.2.6)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (6.5.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (3.1.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (5.3.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.5.7)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.17.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (3.10.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (23.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (2.18.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (4.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.9.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.6.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->skillsnetwork) (2.21)\n",
            "Installing collected packages: jedi, skillsnetwork\n",
            "Successfully installed jedi-0.19.0 skillsnetwork-0.20.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1da2417d-cf35-4426-933e-0f94ab2704b1"
      },
      "source": [
        "## Import Libraries and Packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86e78465-733f-43e0-8404-fe3539697b0e"
      },
      "source": [
        "Let's start the lab by importing the libraries that we will be using in this lab. First we will need the library that helps us to import the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fe98db21-badd-4981-8a56-37f238670c3b"
      },
      "outputs": [],
      "source": [
        "import skillsnetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df933b81-9331-4f83-a691-f4000da40400"
      },
      "source": [
        "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ae3d4906-1ca0-4da4-8e9d-0318c7cf80f3"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feb9d8f2-3a9b-41fe-a4bd-2eb9c0a762f3"
      },
      "source": [
        "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ac3c0af-d7d2-4b86-b360-f43231471500"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feef4bee-e4f2-4ecd-9677-1208dce1700b"
      },
      "source": [
        "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0c1537cb-03a6-4f04-b906-ab9ed76d26ee"
      },
      "outputs": [],
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.applications.resnet import preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cb5437b-c5e6-4967-8de1-c03c746e2ece"
      },
      "source": [
        "<a id='item32'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5819d9d-af9c-429b-914c-64eb76e60ce8"
      },
      "source": [
        "## Download Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d995f70-5dfb-47dd-a116-a11c3235ba8f"
      },
      "source": [
        "In this section, you are going to download the data from IBM object storage using **skillsnetwork.prepare** command. skillsnetwork.prepare is a command that's used to download a zip file, unzip it and store it in a specified directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "1de7f9338b234df0bfd097627f5af9d0",
            "a31169c674d642a699a50557123cde7b",
            "67d11cf2796a485497a51726c8e7c589",
            "5a9e24872aff454dbb8335502ba8b9e2",
            "c7185b7f6826454399918537b11da2a7",
            "9b7b80a94ec3442d99b89d264f3329f1",
            "96910c3464124473b9a2bb62c183576c",
            "6dcabf5d216c49a8982675f43c8bbed3",
            "eceee677c0f74426ae5d36895c85020f",
            "b8bd8aa8d55c444c871276e8c33878b3",
            "d359f673f5744796bb625615db78e90c",
            "082580d445ae4baf9978408f810ac23b",
            "85c1e7f54b9b4f149be465f6423a33f4",
            "8a54432db9b9472ca2159aa535f5853a",
            "9345865816414226b2d59e3be0626743",
            "a5b3c3408bd84f05895ddfe0cc3d552e",
            "30c0b45e7d7046ebbd195bad2e80f01a",
            "1af30de8a42b4efe922cfd1d24b35cde",
            "402252bdbcb247e4bcb2f678cc729bdd",
            "30f32b010a214718a0e517f9557b5a2c",
            "db80a6acf18746b88d817efe00f3bb5b",
            "2211402d17514cdb9f786c8cbd55aeba"
          ]
        },
        "id": "b0ae1a20-2062-4f1b-96ce-6e0674975622",
        "outputId": "212a00ff-e760-497a-c3bf-a670f939a0eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading concrete_data_week3.zip:   0%|          | 0/261482368 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1de7f9338b234df0bfd097627f5af9d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/80037 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "082580d445ae4baf9978408f810ac23b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to '.'\n"
          ]
        }
      ],
      "source": [
        "## get the data\n",
        "await skillsnetwork.prepare(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1adf0e50-909c-4bdb-89d9-c773a89216ed"
      },
      "source": [
        "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d9d9beb-9dd8-4e83-9ca9-9e2c09f19eab"
      },
      "source": [
        "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50** error. So please **DO NOT DO IT**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "366d2205-be27-4b90-82cc-3dd130fd5fd9"
      },
      "source": [
        "<a id='item33'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4533766-4ae0-432e-b6cd-e32b558fadf0"
      },
      "source": [
        "## Define Global Constants\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acfc926b-9b40-4ead-81aa-b6f4e3dbfd88"
      },
      "source": [
        "Here, we will define constants that we will be using throughout the rest of the lab.\n",
        "\n",
        "1. We are obviously dealing with two classes, so *num_classes* is 2.\n",
        "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
        "3. We will training and validating the model using batches of 100 images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eadf578c-16b2-425a-885e-1f5202becc12"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "\n",
        "image_resize = 224\n",
        "\n",
        "batch_size_training = 100\n",
        "batch_size_validation = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddea71c8-954b-4a80-9664-dcaa0d589811"
      },
      "source": [
        "<a id='item34'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a4a47fa-9090-4e6e-8c78-d98b03cfc38d"
      },
      "source": [
        "## Construct ImageDataGenerator Instances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "352ef6bc-0d38-4949-808a-a37b0b051871"
      },
      "source": [
        "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "72a935a2-9f94-42e6-b764-e01de7ac1af9"
      },
      "outputs": [],
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function = preprocess_input,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e7df7c6-d10f-466d-bc7b-738eca43d839"
      },
      "source": [
        "Next, we will use the *flow_from_directory* method to get the training images as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14dd3fdb-bc4e-4af5-8c3b-24292f73dcdf",
        "outputId": "b41b7a08-83b3-4c6a-b48d-6798b1438c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30001 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/train',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_training,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60d98b33-d357-4a11-ad61-63055ba10334"
      },
      "source": [
        "**Note**: in this lab, we will be using the full data-set of 40,000 images for training and validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4537a5e-adcf-4722-95c0-9b277b445bd6"
      },
      "source": [
        "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d4b940f-2dc4-44f0-b26e-a04906e0bcfb",
        "outputId": "6be2fe54-c7e6-42a2-e466-240ad7255ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10001 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "## Type your answer here\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83c9dbef-2907-497a-9d4a-4ad2828a563f"
      },
      "source": [
        "Double-click __here__ for the solution.\n",
        "<!-- The correct answer is:\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical')\n",
        "-->\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5afab31-6a54-43a2-ae3f-6a85e9c5ffe8"
      },
      "source": [
        "<a id='item35'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c20de955-f27d-461c-8c71-9b0189014f71"
      },
      "source": [
        "## Build, Compile and Fit Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ade32f00-7084-47c7-8b46-6350be8350bb"
      },
      "source": [
        "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e6e60cc3-76f1-4096-ab2f-2ea30f49700c"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fdc30dd-813a-4b2c-b23d-e48b0f3b5530"
      },
      "source": [
        "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "391d3165-5d15-407d-bb54-9262b92ddffd",
        "outputId": "555a008c-842c-4eda-c2ad-992278fb3137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model.add(ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet',\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "382b4886-4d8b-4451-baca-462437fb18e6"
      },
      "source": [
        "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3d6f3e8a-b880-44cb-96f6-aaa53a23b987"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79deafb4-323b-4cc6-80e8-97a9d8d3703e"
      },
      "source": [
        "You can access the model's layers using the *layers* attribute of our model object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7a33afa-9d85-47e6-8746-5bf8a6378fae",
        "outputId": "622850d0-cfb3-4409-e625-850f674ab761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.functional.Functional at 0x7d7f5d93a2f0>,\n",
              " <keras.layers.core.dense.Dense at 0x7d7f5d7a1de0>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "934150ad-a32e-4d67-99cb-e3c8c6f63292"
      },
      "source": [
        "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "483de117-cda0-4b1e-bf37-18871f0c8977"
      },
      "source": [
        "You can access the ResNet50 layers by running the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ad07b7-a873-421d-a90f-9f6a8f1644d8",
        "outputId": "6ac594b3-983e-4576-b975-9d50f0ae8d6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7d7f5e31b520>,\n",
              " <keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7d7f5d16d150>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d16d5a0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d16e3b0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d16f250>,\n",
              " <keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7d7f5d16fa30>,\n",
              " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7d7f5c314880>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5c317670>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5c317dc0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f05f60>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f067a0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f07970>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f067d0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5c3169e0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f1ccd0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5c3174f0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f1de10>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f84f1e230>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f1f4c0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f1fd00>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f1fc10>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f1fc40>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f1d9f0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5c314d30>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5c3148e0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f1c880>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f1d7b0>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f84f05030>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f35ba0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f379a0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f37160>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f37d90>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f41000>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f41a80>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f41f30>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f431f0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f43a30>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f84f42e00>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f4d450>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f4f640>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f4fac0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f4d420>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f656c0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f66ec0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f66a40>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f4e6e0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f677c0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f4d300>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f669e0>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f84f67fd0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f81b40>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f82c80>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f82290>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f83df0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f83b20>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f81c30>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f99e10>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f83310>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f81240>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f84f83eb0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f04040>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f06ef0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f05fc0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f43a60>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f40dc0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f05c30>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f66320>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f66fb0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f04430>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f84f1e950>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f1c250>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f36170>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f37a60>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f36590>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f37a00>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d16f0a0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5c317a30>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f9a320>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f99fc0>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5c316950>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f99390>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d855780>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d857820>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d857b20>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8711b0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d871f60>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d872da0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d855330>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d872b00>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8561a0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d870a00>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5d873d60>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d881150>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8821d0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8831f0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d882770>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d883f40>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d882ec0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d882440>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d870430>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d854d60>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5d871630>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f99f60>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f36020>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f07f10>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f84f64b80>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f84f43970>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d882380>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d89d270>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d89f3a0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d89fbe0>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5d89f4f0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8b1600>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8b26b0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8b2aa0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8b3880>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8b3820>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8b35b0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8b5870>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8b6080>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8b6b00>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f84f054b0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8b5bd0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8d4af0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8d5ba0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8d5fc0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8d7010>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8d7be0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8d4ac0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8e8fd0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8ea080>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5d8ea4a0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8eac20>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8ebe20>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8eba30>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8e9540>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d8e8a00>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d8b1150>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d8b0340>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d89fc40>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f84f1e920>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5d8d6f20>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d901ae0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d9029e0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d900e80>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d911ab0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d9101f0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d9135e0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d912b30>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d902c80>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d911c00>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d903af0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d912e00>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5d911d20>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d918d00>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d91b370>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d91bc40>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d91b2b0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d938970>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d939a50>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d939d50>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d93ab60>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d93b3a0>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5d93bf70>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d750dc0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d751f00>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d750c70>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d753040>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d753790>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d751ae0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d769060>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7d7f5d752020>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7d7f5d7504c0>,\n",
              " <keras.layers.merging.add.Add at 0x7d7f5d750cd0>,\n",
              " <keras.layers.core.activation.Activation at 0x7d7f5d9107f0>,\n",
              " <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x7d7f5d912b60>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.layers[0].layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9b50534-db82-48ff-a966-db9c9db20b83"
      },
      "source": [
        "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e9ab99d5-d322-41e7-9c67-7da3d02c0b81"
      },
      "outputs": [],
      "source": [
        "model.layers[0].trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "936f1a04-0bcc-4a29-935e-e20d23cd76cd"
      },
      "source": [
        "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80e16337-42ed-4ee6-ab2c-3fa90719d4ff",
        "outputId": "fc4b6967-67f2-4597-8e6c-d62f03a03929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,591,810\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31c39eb0-b6c6-4f14-9c26-b861e3d071a0"
      },
      "source": [
        "Next we compile our model using the **adam** optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4b9d8738-412b-4b18-afec-ff07dd316960"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74173ec3-81e4-41cb-84f0-047d562b195c"
      },
      "source": [
        "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d0f49844-0ce6-468a-adc0-17c2d9ddbab5"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "num_epochs = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f09403d-0dd1-492b-8630-86fb412f6f5a"
      },
      "source": [
        "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b0dc574-8803-44d7-b3d7-57026a9f74c0",
        "outputId": "eb4609ac-c369-4627-8ed6-6990afc69f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-172e67583a70>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  fit_history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "301/301 [==============================] - 156s 473ms/step - loss: 0.0378 - accuracy: 0.9838 - val_loss: 0.0074 - val_accuracy: 0.9982\n",
            "Epoch 2/2\n",
            "301/301 [==============================] - 128s 426ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9988\n"
          ]
        }
      ],
      "source": [
        "fit_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ddfe7fa-64dc-446e-90f1-4caf95352890"
      },
      "source": [
        "Now that the model is trained, you are ready to start using it to classify images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acff630c-cf29-45b0-be4a-9fbcfb475b42"
      },
      "source": [
        "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0424beb7-0c3f-4bb3-af40-14e852aaa92f"
      },
      "outputs": [],
      "source": [
        "model.save('classifier_resnet_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d02a8457-6201-4efd-9f84-ac65812ba037"
      },
      "source": [
        "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ebb1e58-fe8f-409e-afc8-b4c9dfc97672"
      },
      "source": [
        "### Thank you for completing this lab!\n",
        "\n",
        "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d42d3248-8125-42c9-9a61-4b142ef12e35"
      },
      "source": [
        "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1df79a67-08ce-40dd-9ee4-233b19da1060"
      },
      "source": [
        "\n",
        "## Change Log\n",
        "\n",
        "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
        "|---|---|---|---|\n",
        "| 2020-09-18  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
        "| 2023-01-03  | 3.0  | Artem |  Updated the file import section|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feb23059-dd19-4d06-b9b7-def2386544a6"
      },
      "source": [
        "<hr>\n",
        "\n",
        "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_medium=dswb&utm_source=bducopyrightlink&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1de7f9338b234df0bfd097627f5af9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a31169c674d642a699a50557123cde7b",
              "IPY_MODEL_67d11cf2796a485497a51726c8e7c589",
              "IPY_MODEL_5a9e24872aff454dbb8335502ba8b9e2"
            ],
            "layout": "IPY_MODEL_c7185b7f6826454399918537b11da2a7"
          }
        },
        "a31169c674d642a699a50557123cde7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b7b80a94ec3442d99b89d264f3329f1",
            "placeholder": "​",
            "style": "IPY_MODEL_96910c3464124473b9a2bb62c183576c",
            "value": "Downloading concrete_data_week3.zip: 100%"
          }
        },
        "67d11cf2796a485497a51726c8e7c589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dcabf5d216c49a8982675f43c8bbed3",
            "max": 261482368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eceee677c0f74426ae5d36895c85020f",
            "value": 261482368
          }
        },
        "5a9e24872aff454dbb8335502ba8b9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8bd8aa8d55c444c871276e8c33878b3",
            "placeholder": "​",
            "style": "IPY_MODEL_d359f673f5744796bb625615db78e90c",
            "value": " 261482368/261482368 [00:08&lt;00:00, 30067758.25it/s]"
          }
        },
        "c7185b7f6826454399918537b11da2a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b7b80a94ec3442d99b89d264f3329f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96910c3464124473b9a2bb62c183576c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dcabf5d216c49a8982675f43c8bbed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eceee677c0f74426ae5d36895c85020f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8bd8aa8d55c444c871276e8c33878b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d359f673f5744796bb625615db78e90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "082580d445ae4baf9978408f810ac23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85c1e7f54b9b4f149be465f6423a33f4",
              "IPY_MODEL_8a54432db9b9472ca2159aa535f5853a",
              "IPY_MODEL_9345865816414226b2d59e3be0626743"
            ],
            "layout": "IPY_MODEL_a5b3c3408bd84f05895ddfe0cc3d552e"
          }
        },
        "85c1e7f54b9b4f149be465f6423a33f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30c0b45e7d7046ebbd195bad2e80f01a",
            "placeholder": "​",
            "style": "IPY_MODEL_1af30de8a42b4efe922cfd1d24b35cde",
            "value": "Extracting concrete_data_week3.zip: 100%"
          }
        },
        "8a54432db9b9472ca2159aa535f5853a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_402252bdbcb247e4bcb2f678cc729bdd",
            "max": 80037,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30f32b010a214718a0e517f9557b5a2c",
            "value": 80037
          }
        },
        "9345865816414226b2d59e3be0626743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db80a6acf18746b88d817efe00f3bb5b",
            "placeholder": "​",
            "style": "IPY_MODEL_2211402d17514cdb9f786c8cbd55aeba",
            "value": " 80037/80037 [00:14&lt;00:00, 6841.34it/s]"
          }
        },
        "a5b3c3408bd84f05895ddfe0cc3d552e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c0b45e7d7046ebbd195bad2e80f01a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af30de8a42b4efe922cfd1d24b35cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "402252bdbcb247e4bcb2f678cc729bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f32b010a214718a0e517f9557b5a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db80a6acf18746b88d817efe00f3bb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2211402d17514cdb9f786c8cbd55aeba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}